//
//  SCPhotoSession.swift
//  SparkCamera
//
//  Created by dzw on 2024/12/19.
//

import UIKit
import AVFoundation
import CoreMotion

// MARK: - Focus Enums
public enum SCFocusMode: Int {
    case auto = 0          // å•æ¬¡è‡ªåŠ¨å¯¹ç„¦
    case continuous = 1    // è¿ç»­è‡ªåŠ¨å¯¹ç„¦
    case locked = 2        // é”å®šå¯¹ç„¦
    case manual = 3        // æ‰‹åŠ¨å¯¹ç„¦
}

public enum SCFocusState {
    case focusing       // æ­£åœ¨å¯¹ç„¦
    case focused        // å¯¹ç„¦æˆåŠŸ
    case failed        // å¯¹ç„¦å¤±è´¥
    case locked        // å¯¹ç„¦å·²é”å®š
}

extension SCSession.FlashMode {
    
    var captureFlashMode: AVCaptureDevice.FlashMode {
        switch self {
        case .off: return .off
        case .on: return .on
        case .auto: return .auto
        }
    }
}

@objc public class SCPhotoSession: SCSession, AVCapturePhotoCaptureDelegate, AVCaptureMetadataOutputObjectsDelegate {
    
    @objc public enum CameraDetection: UInt {
        case none, faces
    }
    
    @objc public var cameraPosition: CameraPosition = .back {
        didSet {
            if cameraPosition == oldValue {
                return
            }
            
            configureInputs()
        }
    }
    
    @objc public var cameraDetection = CameraDetection.none {
        didSet {
            if oldValue == self.cameraDetection { return }
            
            for output in self.session.outputs {
                if output is AVCaptureMetadataOutput {
                    self.session.removeOutput(output)
                }
            }
            
            self.faceDetectionBoxes.forEach({ $0.removeFromSuperview() })
            self.faceDetectionBoxes = []
            
            if self.cameraDetection == .faces {
                let metadataOutput = AVCaptureMetadataOutput()
                self.session.addOutput(metadataOutput)
                
                metadataOutput.setMetadataObjectsDelegate(self, queue: .main)
                if metadataOutput.availableMetadataObjectTypes.contains(.face) {
                    metadataOutput.metadataObjectTypes = [.face]
                }
            }
        }
    }
    
    @objc public var flashMode = SCSession.FlashMode.off
    
    var captureDeviceInput: AVCaptureDeviceInput? {
        didSet {
            if let device = captureDeviceInput?.device {
                try? device.lockForConfiguration()
                device.videoZoomFactor = CGFloat(zoom)
                device.unlockForConfiguration()
            }
        }
    }
    
    private var photoOutput: AVCapturePhotoOutput?
    
    var faceDetectionBoxes: [UIView] = []
    
    private var isPreviewLayerSetup = false
    private var isSessionRunning = false
    
    @objc public var resolution: CGSize = .zero {
        didSet {
            print("ğŸ“¸ [Photo Session] è®¾ç½®åˆ†è¾¨ç‡: \(resolution.width) x \(resolution.height)")
            
            // é˜²æ­¢é€’å½’è®¾ç½®
            guard resolution != oldValue else { return }
            
            // å¦‚æœåˆ†è¾¨ç‡ä¸ºé›¶ä¸”æœ‰å¯ç”¨è®¾å¤‡ï¼Œä½¿ç”¨è®¾å¤‡æœ€å¤§åˆ†è¾¨ç‡
            if (resolution.width == 0 || resolution.height == 0),
               let device = videoInput?.device {
                let maxResolution = device.activeFormat.highResolutionStillImageDimensions
                let size = min(CGFloat(maxResolution.width), CGFloat(maxResolution.height))
                print("ğŸ“¸ [Photo Session] ä½¿ç”¨è®¾å¤‡æœ€å¤§åˆ†è¾¨ç‡: \(size) x \(size)")
                self.resolution = CGSize(width: size, height: size)
                return
            }
            
            // å¼€å§‹é…ç½®ä¼šè¯
            session.beginConfiguration()
            
            // è®¡ç®—ç›®æ ‡æ¯”ä¾‹
            let targetAspectRatio = resolution.width / resolution.height
            print("ğŸ“¸ [Photo Session] ç›®æ ‡æ¯”ä¾‹: \(targetAspectRatio)")
            
            // æ ¹æ®ç›®æ ‡æ¯”ä¾‹é€‰æ‹©åˆé€‚çš„é¢„è®¾
            if abs(targetAspectRatio - 3.0/4.0) < 0.01 {
                session.sessionPreset = .photo
                print("ğŸ“¸ [Photo Session] è®¾ç½®ä¼šè¯é¢„è®¾ä¸º: photo (3:4)")
            } else if abs(targetAspectRatio - 9.0/16.0) < 0.01 {
                session.sessionPreset = .hd1920x1080
                print("ğŸ“¸ [Photo Session] è®¾ç½®ä¼šè¯é¢„è®¾ä¸º: 1920x1080 (16:9)")
            } else if abs(targetAspectRatio - 1.0) < 0.01 {
                session.sessionPreset = .high
                print("ğŸ“¸ [Photo Session] è®¾ç½®ä¼šè¯é¢„è®¾ä¸º: high (1:1)")
            }
            
            // é…ç½®ç…§ç‰‡è¾“å‡º
            if let photoOutput = self.photoOutput,
               let connection = photoOutput.connection(with: .video) {
                if connection.isVideoOrientationSupported {
                    connection.videoOrientation = .portrait
                }
            }
            
            session.commitConfiguration()
            
            print("ğŸ“¸ [Photo Session] ä¼šè¯é…ç½®å®Œæˆ")
            print("ğŸ“¸ [Photo Session] - ä¼šè¯é¢„è®¾: \(session.sessionPreset.rawValue)")
            if let photoOutput = self.photoOutput {
                print("ğŸ“¸ [Photo Session] - é«˜åˆ†è¾¨ç‡æ‹æ‘„: \(photoOutput.isHighResolutionCaptureEnabled)")
            }
        }
    }
    
    @objc public init(position: CameraPosition = .back, detection: CameraDetection = .none) {
        super.init()
        
        // åˆå§‹åŒ–ç…§ç‰‡è¾“å‡º
        let photoOutput = AVCapturePhotoOutput()
        self.photoOutput = photoOutput
        
        // é…ç½®ç…§ç‰‡è¾“å‡º
        photoOutput.isHighResolutionCaptureEnabled = true
        print("ğŸ“¸ [Photo Session] åˆå§‹åŒ–ç…§ç‰‡è¾“å‡º:")
        print("ğŸ“¸ [Photo Session] - é«˜åˆ†è¾¨ç‡æ‹æ‘„: \(photoOutput.isHighResolutionCaptureEnabled)")
        
        // æ·»åŠ ç…§ç‰‡è¾“å‡º
        if session.canAddOutput(photoOutput) {
            session.addOutput(photoOutput)
            print("ğŸ“¸ [Photo Session] ç…§ç‰‡è¾“å‡ºå·²æ·»åŠ åˆ°ä¼šè¯")
        } else {
            print("âš ï¸ [Photo Session] æ— æ³•æ·»åŠ ç…§ç‰‡è¾“å‡ºåˆ°ä¼šè¯")
        }
        
        // å¼€å§‹ç›‘å¬è®¾å¤‡æ–¹å‘å˜åŒ–
        startDeviceOrientationNotifier()
        
        // é…ç½®ç›¸æœºä½ç½®å’Œæ£€æµ‹
            self.cameraPosition = position
            self.cameraDetection = detection
        
        // é…ç½®è¾“å…¥è®¾å¤‡å¹¶è®¾ç½®åˆå§‹åˆ†è¾¨ç‡
        configureInputs()
    }
    
    // æ·»åŠ è®¾å¤‡æ–¹å‘ç›‘å¬
    private var deviceOrientationNotifier: Any?
    private var currentDeviceOrientation: UIDeviceOrientation = .portrait
    private let motionManager = CMMotionManager()
    
    private func startDeviceOrientationNotifier() {
        // ç¡®ä¿è®¾å¤‡æ”¯æŒé™€èºä»ª
        guard motionManager.isDeviceMotionAvailable else {
            print("âš ï¸ [Orientation] è®¾å¤‡ä¸æ”¯æŒè¿åŠ¨æ£€æµ‹")
            return
        }
        
        // è®¾ç½®æ›´æ–°é¢‘ç‡
        motionManager.deviceMotionUpdateInterval = 0.5
        
        // å¼€å§‹ç›‘å¬è®¾å¤‡è¿åŠ¨
        motionManager.startDeviceMotionUpdates(to: .main) { [weak self] (motion, error) in
            guard let self = self,
                  let motion = motion else {
                if let error = error {
                    print("âš ï¸ [Orientation] è¿åŠ¨æ›´æ–°é”™è¯¯: \(error.localizedDescription)")
                }
                return
            }
            
            // è·å–é‡åŠ›å‘é‡
            let gravity = motion.gravity
            
            // æ ¹æ®é‡åŠ›æ–¹å‘åˆ¤æ–­è®¾å¤‡æ–¹å‘
            let orientation: UIDeviceOrientation
            if gravity.z < -0.75 {
                orientation = .faceUp
            } else if gravity.z > 0.75 {
                orientation = .faceDown
            } else {
                let x = gravity.x
                let y = gravity.y
                
                if abs(y) < 0.45 {
                    orientation = x < 0 ? .landscapeRight : .landscapeLeft
                } else {
                    orientation = y < 0 ? .portrait : .portraitUpsideDown
                }
            }
            
            // å¦‚æœæ–¹å‘å‘ç”Ÿå˜åŒ–ï¼Œæ›´æ–°å½“å‰æ–¹å‘
            if orientation != self.currentDeviceOrientation {
                self.currentDeviceOrientation = orientation
                print("ğŸ“¸ [Orientation] è®¾å¤‡æ–¹å‘æ›´æ–°: \(orientation.rawValue)")
            }
        }
        
        print("ğŸ“¸ [Orientation] å¼€å§‹ç›‘å¬è®¾å¤‡æ–¹å‘")
    }
    
    deinit {
        // åœæ­¢è¿åŠ¨æ›´æ–°
        motionManager.stopDeviceMotionUpdates()
        print("ğŸ“¸ [Orientation] åœæ­¢ç›‘å¬è®¾å¤‡æ–¹å‘")
    }
    
    // å›è°ƒé—­åŒ…
    public var captureCallback: ((UIImage, [String: Any]) -> Void)?
    public var errorCallback: ((Error) -> Void)?
    
    @objc public func capture(_ callback: @escaping (UIImage, [String: Any]) -> Void, _ error: @escaping (Error) -> Void) {
        self.captureCallback = callback
        self.errorCallback = error
        
        guard let photoOutput = self.photoOutput else {
            error(SCError.error("Photo output not available"))
            return
        }
        
        // é…ç½®ç…§ç‰‡è®¾ç½®
        let photoSettings = AVCapturePhotoSettings()
        
        // æ£€æŸ¥å¹¶è®¾ç½®é—ªå…‰ç¯
        if let device = self.videoInput?.device,
           device.hasFlash {
            if device.isFlashAvailable {
                photoSettings.flashMode = AVCaptureDevice.FlashMode(rawValue: Int(self.flashMode.rawValue)) ?? .auto
            }
        }
        
        // é…ç½®é«˜è´¨é‡æ•è·
        photoSettings.isHighResolutionPhotoEnabled = photoOutput.isHighResolutionCaptureEnabled
        
        // å¼€å§‹æ‹ç…§
        print("ğŸ“¸ [Photo Session] å¼€å§‹æ‹ç…§...")
        print("ğŸ“¸ [Photo Session] - é«˜åˆ†è¾¨ç‡æ‹æ‘„: \(photoSettings.isHighResolutionPhotoEnabled)")
        photoOutput.capturePhoto(with: photoSettings, delegate: self)
    }
    
    @objc public func togglePosition() {
        self.cameraPosition = self.cameraPosition == .back ? .front : .back
    }
    
    @objc public override var zoom: Double {
        didSet {
            guard let device = self.captureDeviceInput?.device else {
                return
            }
            
            do {
                try device.lockForConfiguration()
                device.videoZoomFactor = CGFloat(self.zoom)
                device.unlockForConfiguration()
            } catch {
                //
            }
            
            if let delegate = self.delegate {
                delegate.didChangeValue(session: self, value: self.zoom, key: "zoom")
            }
        }
    }
    
    @objc public override func focus(at point: CGPoint) {
        guard let device = captureDeviceInput?.device else { return }
        
        do {
            try device.lockForConfiguration()
            
            // æ›´æ–°å¯¹ç„¦çŠ¶æ€
            focusState = .focusing
            
            // è®¾ç½®å¯¹ç„¦ç‚¹
            if device.isFocusPointOfInterestSupported {
                device.focusPointOfInterest = point
                print("ğŸ“¸ [Focus] è®¾ç½®å¯¹ç„¦ç‚¹ï¼š\(point)")
            }
            
            // æ ¹æ®å½“å‰æ¨¡å¼è®¾ç½®å¯¹ç„¦
            switch focusMode {
            case .auto:
                if device.isFocusModeSupported(.autoFocus) {
                    device.focusMode = .autoFocus
                }
            case .continuous:
                if device.isFocusModeSupported(.continuousAutoFocus) {
                    device.focusMode = .continuousAutoFocus
                }
            case .locked:
                if device.isFocusModeSupported(.locked) {
                    device.focusMode = .locked
                }
            case .manual:
                // æ‰‹åŠ¨å¯¹ç„¦æ¨¡å¼å°†åœ¨åç»­å®ç°
                break
            }
            
            // æ·»åŠ å¯¹ç„¦è§‚å¯Ÿè€…
            NotificationCenter.default.addObserver(self,
                                                 selector: #selector(subjectAreaDidChange),
                                                 name: .AVCaptureDeviceSubjectAreaDidChange,
                                                 object: device)
            
            device.unlockForConfiguration()
            
            // å»¶è¿Ÿæ›´æ–°å¯¹ç„¦çŠ¶æ€
            DispatchQueue.main.asyncAfter(deadline: .now() + 1.0) { [weak self] in
                self?.focusState = .focused
            }
            
            print("ğŸ“¸ [Focus] å¯¹ç„¦æ¨¡å¼ï¼š\(focusMode)")
            
        } catch {
            print("âš ï¸ [Focus] è®¾ç½®å¯¹ç„¦å¤±è´¥: \(error.localizedDescription)")
            focusState = .failed
        }
    }
    
    @objc private func subjectAreaDidChange(notification: NSNotification) {
        // ä¸»ä½“åŒºåŸŸå‘ç”Ÿå˜åŒ–æ—¶ï¼Œå¦‚æœæ˜¯è¿ç»­å¯¹ç„¦æ¨¡å¼ï¼Œæ›´æ–°å¯¹ç„¦çŠ¶æ€
        if focusMode == .continuous {
            focusState = .focusing
            
            // å»¶è¿Ÿæ›´æ–°çŠ¶æ€
            DispatchQueue.main.asyncAfter(deadline: .now() + 0.5) { [weak self] in
                self?.focusState = .focused
            }
        }
    }
    
    // è®¾ç½®å¯¹ç„¦æ¨¡å¼
    public func setFocusMode(_ mode: SCFocusMode) {
        focusMode = mode
        print("ğŸ“¸ [Focus] åˆ‡æ¢å¯¹ç„¦æ¨¡å¼ï¼š\(mode)")
    }
    
    // é”å®šå½“å‰å¯¹ç„¦
    public func lockFocus() {
        setFocusMode(.locked)
        focusState = .locked
        print("ğŸ“¸ [Focus] é”å®šå¯¹ç„¦")
    }
    
    // è§£é”å¯¹ç„¦
    public func unlockFocus() {
        setFocusMode(.continuous)
        print("ğŸ“¸ [Focus] è§£é”å¯¹ç„¦")
    }
    
    @available(iOS 11.0, *)
    public func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photo: AVCapturePhoto, error: Error?) {
        if let error = error {
            print("âŒ [Photo Session] å¤„ç†ç…§ç‰‡æ—¶å‡ºé”™: \(error.localizedDescription)")
            self.errorCallback?(error)
            return
        }
        
        guard let imageData = photo.fileDataRepresentation() else {
            print("âŒ [Photo Session] æ— æ³•è·å–å›¾ç‰‡æ•°æ®")
            self.errorCallback?(SCError.error("Cannot get photo file data representation"))
            return
        }
        
        print("ğŸ“¸ [Photo Session] ç…§ç‰‡ä¿¡æ¯:")
        print("ğŸ“¸ [Photo Session] - æ•°æ®å¤§å°: \(Double(imageData.count) / 1024.0 / 1024.0) MB")
        
        // è·å–ç…§ç‰‡åˆ†è¾¨ç‡
        if let cgImage = UIImage(data: imageData)?.cgImage {
            print("ğŸ“¸ [Photo Session] - å®é™…åˆ†è¾¨ç‡: \(cgImage.width) x \(cgImage.height)")
        }
        
        // å¤„ç†ç…§ç‰‡æ•°æ®
        self.processPhotoData(imageData)
    }
    
    public func photoOutput(_ output: AVCapturePhotoOutput, didFinishProcessingPhoto photoSampleBuffer: CMSampleBuffer?, previewPhoto previewPhotoSampleBuffer: CMSampleBuffer?, resolvedSettings: AVCaptureResolvedPhotoSettings, bracketSettings: AVCaptureBracketedStillImageSettings?, error: Error?) {
        if let error = error {
            self.errorCallback?(error)
            return
        }

        guard
            let photoSampleBuffer = photoSampleBuffer,
            let previewPhotoSampleBuffer = previewPhotoSampleBuffer,
            let data = AVCapturePhotoOutput.jpegPhotoDataRepresentation(forJPEGSampleBuffer: photoSampleBuffer, previewPhotoSampleBuffer: previewPhotoSampleBuffer) else
        {
            self.errorCallback?(SCError.error("Cannot get photo file data representation"))
            return
        }

        self.processPhotoData(data)
    }
    
    func processPhotoData(_ data: Data) {
        print("ğŸ“¸ [Photo Session] ===== å¤„ç†ç…§ç‰‡æ•°æ® =====")
        print("ğŸ“¸ [Photo Session] - æ•°æ®å¤§å°: \(Double(data.count) / 1024.0 / 1024.0) MB")
        
        guard let image = UIImage(data: data) else {
            print("âŒ [Photo Session] æ— æ³•ä»æ•°æ®åˆ›å»ºå›¾åƒ")
            self.errorCallback?(SCError.error("Cannot create image from data"))
            return
        }
        
        print("ğŸ“¸ [Photo Session] åŸå§‹å›¾ç‰‡ä¿¡æ¯:")
        print("ğŸ“¸ [Photo Session] - å°ºå¯¸: \(image.size.width) x \(image.size.height)")
        print("ğŸ“¸ [Photo Session] - æ–¹å‘: \(image.imageOrientation.rawValue)")
        
        // å¼‚æ­¥å¤„ç†å›¾åƒ
        DispatchQueue.global(qos: .userInitiated).async { [weak self] in
            guard let self = self else { return }
            
            // è·å–å½“å‰è®¾å¤‡æ–¹å‘
            let deviceOrientation = self.currentDeviceOrientation
            print("ğŸ“¸ [Photo Process] è®¾å¤‡æ–¹å‘: \(deviceOrientation.rawValue)")
            
            // ç¡®å®šå›¾ç‰‡æ–¹å‘
            let imageOrientation: UIImage.Orientation = {
                // å¦‚æœæ˜¯æ¨ªå±æ‹æ‘„ï¼ˆå®½å¤§äºé«˜ï¼‰ï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                let isLandscape = image.size.width > image.size.height
                
                switch deviceOrientation {
                case .portrait:
                    if isLandscape {
                        return self.cameraPosition == .front ? .leftMirrored : .left
                    }
                    return self.cameraPosition == .front ? .rightMirrored : .right
                case .portraitUpsideDown:
                    if isLandscape {
                        return self.cameraPosition == .front ? .rightMirrored : .right
                    }
                    return self.cameraPosition == .front ? .leftMirrored : .left
                case .landscapeLeft:
                    return self.cameraPosition == .front ? .downMirrored : .down
                case .landscapeRight:
                    return self.cameraPosition == .front ? .upMirrored : .up
                case .faceUp, .faceDown:
                    // å¦‚æœè®¾å¤‡å¹³æ”¾ï¼Œä½¿ç”¨é¢„è§ˆå±‚çš„æ–¹å‘
                    if let connection = self.previewLayer?.connection,
                       connection.isVideoOrientationSupported {
                        switch connection.videoOrientation {
                        case .portrait:
                            if isLandscape {
                                return self.cameraPosition == .front ? .leftMirrored : .left
                            }
                            return self.cameraPosition == .front ? .rightMirrored : .right
                        case .portraitUpsideDown:
                            if isLandscape {
                                return self.cameraPosition == .front ? .rightMirrored : .right
                            }
                            return self.cameraPosition == .front ? .leftMirrored : .left
                        case .landscapeLeft:
                            return self.cameraPosition == .front ? .upMirrored : .up
                        case .landscapeRight:
                            return self.cameraPosition == .front ? .downMirrored : .down
                        @unknown default:
                            if isLandscape {
                                return self.cameraPosition == .front ? .leftMirrored : .left
                            }
                            return self.cameraPosition == .front ? .rightMirrored : .right
                        }
                    }
                    if isLandscape {
                        return self.cameraPosition == .front ? .leftMirrored : .left
                    }
                    return self.cameraPosition == .front ? .rightMirrored : .right
                default:
                    if isLandscape {
                        return self.cameraPosition == .front ? .leftMirrored : .left
                    }
                    return self.cameraPosition == .front ? .rightMirrored : .right
                }
            }()
            
            print("ğŸ“¸ [Photo Process] ç›®æ ‡å›¾ç‰‡æ–¹å‘: \(imageOrientation.rawValue)")
            
            // 1. åˆ›å»ºæ­£ç¡®æ–¹å‘çš„å›¾ç‰‡
            let cgImage = image.cgImage!
            let orientedImage = UIImage(cgImage: cgImage, scale: image.scale, orientation: imageOrientation)
            
            print("ğŸ“¸ [Photo Process] è°ƒæ•´æ–¹å‘åçš„å›¾ç‰‡å°ºå¯¸: \(orientedImage.size.width) x \(orientedImage.size.height)")
            
            // 2. ç¡®å®šç›®æ ‡è£å‰ªæ¯”ä¾‹
            enum CropAspectRatio: CGFloat {
                case ratio3x4 = 0.75      // 3:4
                case ratio9x16 = 0.5625   // 9:16
                case ratio1x1 = 1.0       // 1:1
                
                var description: String {
                    switch self {
                    case .ratio3x4: return "3:4"
                    case .ratio9x16: return "9:16"
                    case .ratio1x1: return "1:1"
                    }
                }
                
                var inverse: CGFloat {
                    switch self {
                    case .ratio3x4: return 4.0/3.0  // 1.333...
                    case .ratio9x16: return 16.0/9.0  // 1.777...
                    case .ratio1x1: return 1.0
                    }
                }
            }
            
            // ä½¿ç”¨é¢„è§ˆè§†å›¾çš„æ¯”ä¾‹
            let previewRatio = self.resolution.width / self.resolution.height
            let targetRatio: CropAspectRatio = {
                // æ ¹æ®é¢„è§ˆæ¯”ä¾‹ç¡®å®šç›®æ ‡è£å‰ªæ¯”ä¾‹
                if abs(previewRatio - 1.0) < 0.01 {
                    return .ratio1x1
                } else if abs(previewRatio - 0.75) < 0.01 {
                    return .ratio3x4
                } else if abs(previewRatio - 0.5625) < 0.01 {
                    return .ratio9x16
        } else {
                    // é»˜è®¤ä½¿ç”¨ 1:1
                    return .ratio1x1
                }
            }()
            
            print("ğŸ“¸ [Photo Process] é¢„è§ˆæ¯”ä¾‹: \(previewRatio) [resolution]:\(self.resolution)")
            print("ğŸ“¸ [Photo Process] ç›®æ ‡è£å‰ªæ¯”ä¾‹: \(targetRatio.description) (\(targetRatio.rawValue))")
            
            // 3. è®¡ç®—è£å‰ªåŒºåŸŸ
            let cropRect: CGRect = {
                let imageWidth = orientedImage.size.width
                let imageHeight = orientedImage.size.height
                
                // æ ¹æ®å›¾ç‰‡æ–¹å‘è°ƒæ•´å®½é«˜æ¯”è®¡ç®—
                let isRotated = orientedImage.imageOrientation == .right || orientedImage.imageOrientation == .left
                let effectiveWidth = isRotated ? imageHeight : imageWidth
                let effectiveHeight = isRotated ? imageWidth : imageHeight
                let currentRatio = effectiveWidth / effectiveHeight
                
                print("ğŸ“¸ [Photo Process] å›¾ç‰‡ä¿¡æ¯:")
                print("ğŸ“¸ [Photo Process] - åŸå§‹å°ºå¯¸: \(imageWidth) x \(imageHeight)")
                print("ğŸ“¸ [Photo Process] - æœ‰æ•ˆå°ºå¯¸: \(effectiveWidth) x \(effectiveHeight)")
                print("ğŸ“¸ [Photo Process] - å½“å‰æ¯”ä¾‹: \(currentRatio)")
                
                // æ£€æŸ¥æ˜¯å¦éœ€è¦è£å‰ª
                let needsCrop: Bool = {
                    switch targetRatio {
                    case .ratio1x1:
                        // 1:1æ¨¡å¼æ€»æ˜¯éœ€è¦è£å‰ªæˆæ­£æ–¹å½¢
                        return true
                    case .ratio9x16:
                        // 16:9æ¨¡å¼ï¼Œå¦‚æœæ˜¯16:9æˆ–9:16ä¸è£å‰ª
                        let ratio16_9 = 16.0/9.0
                        let ratio9_16 = 9.0/16.0
                        return !(abs(currentRatio - ratio16_9) < 0.01 || abs(currentRatio - ratio9_16) < 0.01)
                    case .ratio3x4:
                        // 4:3æ¨¡å¼ï¼Œå¦‚æœæ˜¯4:3æˆ–3:4ä¸è£å‰ª
                        let ratio4_3 = 4.0/3.0
                        let ratio3_4 = 3.0/4.0
                        return !(abs(currentRatio - ratio4_3) < 0.01 || abs(currentRatio - ratio3_4) < 0.01)
                    }
                }()
                
                if !needsCrop {
                    print("ğŸ“¸ [Photo Process] å›¾ç‰‡æ¯”ä¾‹å·²åŒ¹é…ç›®æ ‡æ¯”ä¾‹ \(targetRatio.description)ï¼Œæ— éœ€è£å‰ª")
                    return CGRect(origin: .zero, size: orientedImage.size)
                }
                
                var rect: CGRect
                
                // è®¡ç®—ç›®æ ‡æ¯”ä¾‹
                let targetAspectRatio: CGFloat = {
                    switch targetRatio {
                    case .ratio1x1:
                        return 1.0
                    case .ratio9x16:
                        return currentRatio > 1.0 ? 16.0/9.0 : 9.0/16.0
                    case .ratio3x4:
                        return currentRatio > 1.0 ? 4.0/3.0 : 3.0/4.0
                    }
                }()
                
                // å±…ä¸­è£å‰ª
                if currentRatio > targetAspectRatio {
                    // å›¾ç‰‡å¤ªå®½ï¼Œä»ä¸¤è¾¹è£å‰ª
                    let targetWidth = effectiveHeight * targetAspectRatio
                    let xOffset = (effectiveWidth - targetWidth) / 2
                    if isRotated {
                        rect = CGRect(x: 0, y: xOffset, width: imageWidth, height: targetWidth)
            } else {
                        rect = CGRect(x: xOffset, y: 0, width: targetWidth, height: imageHeight)
                    }
                    } else {
                    // å›¾ç‰‡å¤ªé«˜ï¼Œä»ä¸Šä¸‹è£å‰ª
                    let targetHeight = effectiveWidth / targetAspectRatio
                    let yOffset = (effectiveHeight - targetHeight) / 2
                    if isRotated {
                        rect = CGRect(x: yOffset, y: 0, width: targetHeight, height: imageHeight)
                    } else {
                        rect = CGRect(x: 0, y: yOffset, width: imageWidth, height: targetHeight)
                    }
                }
                
                print("ğŸ“¸ [Photo Process] è£å‰ªä¿¡æ¯:")
                print("ğŸ“¸ [Photo Process] - ç›®æ ‡æ¯”ä¾‹: \(targetAspectRatio)")
                print("ğŸ“¸ [Photo Process] - è£å‰ªåŒºåŸŸ: \(rect)")
                
                return rect
            }()
            
            print("ğŸ“¸ [Photo Process] è£å‰ªåŒºåŸŸ: \(cropRect)")
            print("ğŸ“¸ [Photo Process] è£å‰ªåå®½é«˜æ¯”: \(cropRect.width / cropRect.height)")
//#warning("æµ‹è¯•ä»£ç ")
//#if DEBUG//debugä»£ç 
//            let debugImageInfo: [String: Any] = [
//                "aspectRatio": image.size.width / image.size.height,
//                "isLandscape": image.size.width > image.size.height,
//                "width": image.size.width,
//                "height": image.size.height,
//                "orientation": image.imageOrientation.rawValue
//            ]
//            DispatchQueue.main.async {
//                if let callback = self.captureCallback {
//                    callback(image, debugImageInfo)
//                }
//            }
//            return
//#endif
            // 4. æ‰§è¡Œè£å‰ª
            if cropRect == CGRect(origin: .zero, size: orientedImage.size) {
                print("ğŸ“¸ [Photo Process] æ— éœ€è£å‰ªï¼Œä½¿ç”¨åŸå§‹å›¾ç‰‡")
                let photoInfo = SCPhotoInfo(image: orientedImage)
                print(photoInfo.description)
                DispatchQueue.main.async {
                    self.captureCallback?(orientedImage, photoInfo.dictionary)
                }
                return
            }
            
            // æ ¹æ®å›¾ç‰‡æ–¹å‘è°ƒæ•´è£å‰ªåŒºåŸŸ
            let adjustedCropRect: CGRect
            if orientedImage.imageOrientation == .right || orientedImage.imageOrientation == .left {
                // å¯¹äºæ—‹è½¬çš„å›¾ç‰‡ï¼Œäº¤æ¢è£å‰ªåŒºåŸŸçš„å®½é«˜ï¼Œå¹¶ä¿æŒå±…ä¸­
                let xOffset = cropRect.minY
                let yOffset = cropRect.minX
                let width = cropRect.height
                let height = cropRect.width
                adjustedCropRect = CGRect(
                    x: xOffset,
                    y: yOffset,
                    width: width,
                    height: height
                )
                print("ğŸ“¸ [Photo Process] è°ƒæ•´åçš„è£å‰ªåŒºåŸŸ: \(adjustedCropRect)")
                print("ğŸ“¸ [Photo Process] - xåç§»: \(xOffset), yåç§»: \(yOffset)")
                print("ğŸ“¸ [Photo Process] - å®½åº¦: \(width), é«˜åº¦: \(height)")
            } else {
                adjustedCropRect = cropRect
                print("ğŸ“¸ [Photo Process] ä¿æŒåŸå§‹è£å‰ªåŒºåŸŸ: \(adjustedCropRect)")
                print("ğŸ“¸ [Photo Process] - xåç§»: \(cropRect.minX), yåç§»: \(cropRect.minY)")
                print("ğŸ“¸ [Photo Process] - å®½åº¦: \(cropRect.width), é«˜åº¦: \(cropRect.height)")
            }
            
            guard let croppedCGImage = orientedImage.cgImage?.cropping(to: adjustedCropRect) else {
                print("âš ï¸ [Photo Process] è£å‰ªå¤±è´¥ï¼Œä½¿ç”¨åŸå§‹å›¾ç‰‡")
                let photoInfo = SCPhotoInfo(image: orientedImage)
                print(photoInfo.description)
                DispatchQueue.main.async {
                    self.captureCallback?(orientedImage, photoInfo.dictionary)
                }
                return
            }
            
            // 5. åˆ›å»ºæœ€ç»ˆå›¾ç‰‡ï¼Œä¿æŒåŸå§‹æ–¹å‘
            let finalImage = UIImage(cgImage: croppedCGImage, scale: orientedImage.scale, orientation: orientedImage.imageOrientation)
            
            // åˆ›å»ºç…§ç‰‡ä¿¡æ¯
            let photoInfo = SCPhotoInfo(image: finalImage)
            print(photoInfo.description)
            
            DispatchQueue.main.async {
                self.captureCallback?(finalImage, photoInfo.dictionary)
                print("ğŸ“¸ [Photo Session] ===== ç…§ç‰‡å¤„ç†å®Œæˆ =====")
            }
        }
    }
    
    public func metadataOutput(_ output: AVCaptureMetadataOutput, didOutput metadataObjects: [AVMetadataObject], from connection: AVCaptureConnection) {
        let faceMetadataObjects = metadataObjects.filter({ $0.type == .face })
        
        if faceMetadataObjects.count > self.faceDetectionBoxes.count {
            for _ in 0..<faceMetadataObjects.count - self.faceDetectionBoxes.count {
                let view = UIView()
                view.layer.borderColor = UIColor.green.cgColor
                view.layer.borderWidth = 1
                self.overlayView?.addSubview(view)
                self.faceDetectionBoxes.append(view)
            }
        } else if faceMetadataObjects.count < self.faceDetectionBoxes.count {
            for _ in 0..<self.faceDetectionBoxes.count - faceMetadataObjects.count {
                self.faceDetectionBoxes.popLast()?.removeFromSuperview()
            }
        }
        
        for i in 0..<faceMetadataObjects.count {
            if let transformedMetadataObject = self.previewLayer?.transformedMetadataObject(for: faceMetadataObjects[i]) {
                self.faceDetectionBoxes[i].frame = transformedMetadataObject.bounds
            } else {
                self.faceDetectionBoxes[i].frame = CGRect.zero
            }
        }
    }
    
    private func configureInputs() {
        session.beginConfiguration()
        
        // ç§»é™¤ç°æœ‰è¾“å…¥
        for input in session.inputs {
            session.removeInput(input)
        }
        
        // ç§»é™¤ç°æœ‰è¾“å‡º
        for output in session.outputs {
            session.removeOutput(output)
        }
        
        // é‡æ–°åˆ›å»ºå’Œé…ç½®ç…§ç‰‡è¾“å‡º
        let newPhotoOutput = AVCapturePhotoOutput()
        if session.canAddOutput(newPhotoOutput) {
            session.addOutput(newPhotoOutput)
            photoOutput = newPhotoOutput
            
            // é…ç½®ç…§ç‰‡è¾“å‡º
            newPhotoOutput.isHighResolutionCaptureEnabled = true
            if let connection = newPhotoOutput.connection(with: .video) {
                if connection.isVideoOrientationSupported {
                    connection.videoOrientation = .portrait
                }
            }
            
            print("ğŸ“¸ [Photo Session] ç…§ç‰‡è¾“å‡ºå·²æ·»åŠ åˆ°ä¼šè¯")
            print("ğŸ“¸ [Photo Session] - é«˜åˆ†è¾¨ç‡æ‹æ‘„: \(newPhotoOutput.isHighResolutionCaptureEnabled)")
        } else {
            print("âš ï¸ [Photo Session] æ— æ³•æ·»åŠ ç…§ç‰‡è¾“å‡ºåˆ°ä¼šè¯")
        }
        
        do {
            let deviceInput = try SCSession.captureDeviceInput(type: cameraPosition.deviceType)
            if session.canAddInput(deviceInput) {
                session.addInput(deviceInput)
                self.captureDeviceInput = deviceInput
                
                // è·å–è®¾å¤‡æ”¯æŒçš„æœ€å¤§åˆ†è¾¨ç‡
                let maxResolution = deviceInput.device.activeFormat.highResolutionStillImageDimensions
                let maxSize = min(CGFloat(maxResolution.width), CGFloat(maxResolution.height))
                
                // æ ¹æ®å½“å‰æ¯”ä¾‹æ¨¡å¼è®¾ç½®åˆ†è¾¨ç‡
                if self.resolution.width == 0 || self.resolution.height == 0 {
                    let ratioMode = SCCameraSettingsManager.shared.ratioMode
                    let targetSize: CGSize
                    
                    switch ratioMode {
                    case 0: // 4:3
                        targetSize = CGSize(width: maxSize * 0.75, height: maxSize)
                    case 1: // 1:1
                        targetSize = CGSize(width: maxSize, height: maxSize)
                    case 2: // 16:9
                        targetSize = CGSize(width: maxSize * 0.5625, height: maxSize)
                    default:
                        targetSize = CGSize(width: maxSize * 0.75, height: maxSize)
                    }
                    
                    print("ğŸ“¸ [Photo Session] æ ¹æ®æ¯”ä¾‹æ¨¡å¼[\(ratioMode)]è®¾ç½®åˆå§‹åˆ†è¾¨ç‡: \(targetSize.width) x \(targetSize.height)")
                    self.resolution = targetSize
                }
            }
        } catch {
            print("Error configuring camera input: \(error.localizedDescription)")
        }
        
        session.commitConfiguration()
    }

    override func setupPreviewLayer(in view: UIView, completion: (() -> Void)? = nil) {
        guard !isPreviewLayerSetup else { return }
        
        let startTime = Date()
        print("â±ï¸ [Preview Setup] Started at: \(startTime)")
        
        // 1. åˆ›å»ºé¢„è§ˆå±‚
        let previewLayer = AVCaptureVideoPreviewLayer(session: self.session)
        print("â±ï¸ [Preview Setup] Preview layer created: +\(Date().timeIntervalSince(startTime))s")
        
        // 2. åœ¨ä¸»çº¿ç¨‹è®¾ç½®UI
        DispatchQueue.main.async { [weak self] in
            guard let self = self else { return }
            
            previewLayer.videoGravity = .resizeAspectFill
            previewLayer.frame = view.bounds
            view.layer.insertSublayer(previewLayer, at: 0)
            self.previewLayer = previewLayer
            self.isPreviewLayerSetup = true
            print("â±ï¸ [Preview Setup] Preview layer configured: +\(Date().timeIntervalSince(startTime))s")
            
            // 3. åœ¨åå°çº¿ç¨‹å¯åŠ¨ä¼šè¯
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                guard let self = self else { return }
                if !self.isSessionRunning {
                    print("â±ï¸ [Preview Setup] Starting session: +\(Date().timeIntervalSince(startTime))s")
                    self.session.startRunning()
                    self.isSessionRunning = true
                    print("â±ï¸ [Preview Setup] Session started: +\(Date().timeIntervalSince(startTime))s")
                    
                    // ç¡®ä¿ä¼šè¯å¯åŠ¨åå†æ¬¡æ£€æŸ¥åˆ†è¾¨ç‡
                    DispatchQueue.main.async { [weak self] in
                        guard let self = self else { return }
                        if self.resolution.width == 0 || self.resolution.height == 0,
                           let device = self.videoInput?.device {
                            let maxResolution = device.activeFormat.highResolutionStillImageDimensions
                            let maxSize = min(CGFloat(maxResolution.width), CGFloat(maxResolution.height))
                            
                            // æ ¹æ®å½“å‰æ¯”ä¾‹æ¨¡å¼è®¾ç½®åˆ†è¾¨ç‡
                            let ratioMode = SCCameraSettingsManager.shared.ratioMode
                            let targetSize: CGSize
                            
                            switch ratioMode {
                            case 0: // 4:3
                                targetSize = CGSize(width: maxSize * 0.75, height: maxSize)
                            case 1: // 1:1
                                targetSize = CGSize(width: maxSize, height: maxSize)
                            case 2: // 16:9
                                targetSize = CGSize(width: maxSize * 0.5625, height: maxSize)
                            default:
                                targetSize = CGSize(width: maxSize * 0.75, height: maxSize)
                            }
                            
                            print("ğŸ“¸ [Preview Setup] æ ¹æ®æ¯”ä¾‹æ¨¡å¼[\(ratioMode)]è®¾ç½®åˆ†è¾¨ç‡: \(targetSize.width) x \(targetSize.height)")
                            self.resolution = targetSize
                        }
                        print("â±ï¸ [Preview Setup] Setup completed: +\(Date().timeIntervalSince(startTime))s")
                        completion?()
                    }
                }
            }
        }
    }

    // MARK: - Focus Methods
    private func loadFocusSettings() {
        let settings = SCCameraSettingsManager.shared
        focusMode = settings.focusMode
        
        if settings.isFocusLocked {
            lockFocus()
        }
    }

    // MARK: - Session Setup
    private func setupSession() {
        session.beginConfiguration()
        
        // è®¾ç½®ä¼šè¯è´¨é‡
        session.sessionPreset = .photo
        
        // è®¾ç½®è§†é¢‘è¾“å…¥
        guard let device = AVCaptureDevice.default(.builtInWideAngleCamera, for: .video, position: .back) else {
            print("æ— æ³•è·å–ç›¸æœºè®¾å¤‡")
            session.commitConfiguration()
            return
        }
        
        do {
            videoInput = try AVCaptureDeviceInput(device: device)
            if session.canAddInput(videoInput!) {
                session.addInput(videoInput!)
            }
        } catch {
            print("è®¾ç½®è§†é¢‘è¾“å…¥å¤±è´¥: \(error)")
            session.commitConfiguration()
            return
        }
        
        // è®¾ç½®ç…§ç‰‡è¾“å‡º
        photoOutput = AVCapturePhotoOutput()
        if session.canAddOutput(photoOutput!) {
            session.addOutput(photoOutput!)
        }
        
        session.commitConfiguration()
    }
    
    // MARK: - Session Control
    func startSession() {
        // ç¡®ä¿åœ¨åå°çº¿ç¨‹è°ƒç”¨
        if Thread.isMainThread {
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.startSession()
            }
            return
        }
        
        if !session.isRunning {
            session.startRunning()
        }
    }
    
    func stopSession() {
        // ç¡®ä¿åœ¨åå°çº¿ç¨‹è°ƒç”¨
        if Thread.isMainThread {
            DispatchQueue.global(qos: .userInitiated).async { [weak self] in
                self?.stopSession()
            }
            return
        }
        
        if session.isRunning {
            session.stopRunning()
        }
    }

    // MARK: - Flash Control
    func setFlashMode(_ mode: AVCaptureDevice.FlashMode) -> Bool {
        guard let device = captureDeviceInput?.device else { return false }
        
        do {
            try device.lockForConfiguration()
            if device.hasFlash && device.isFlashAvailable {
                device.flashMode = mode
                device.unlockForConfiguration()
                return true
            } else {
                device.unlockForConfiguration()
                return false
            }
            print("è®¾ç½®é—ªå…‰ç¯æ¨¡å¼ä¸ºï¼š\(mode)")
        } catch {
            print("è®¾ç½®é—ªå…‰ç¯å¤±è´¥: \(error)")
            return false
        }
    }
    
    var isFlashAvailable: Bool {
        guard let device = captureDeviceInput?.device else { return false }
        return device.hasFlash && device.isFlashAvailable
    }
    
    var currentFlashMode: AVCaptureDevice.FlashMode? {
        return captureDeviceInput?.device.flashMode
    }

    public func setWhiteBalanceMode(_ state: SCWhiteBalanceState) -> Bool {
        guard let device = captureDeviceInput?.device else { return false }
        
        do {
            try device.lockForConfiguration()
            
            switch state {
            case .auto:
                if device.isWhiteBalanceModeSupported(.continuousAutoWhiteBalance) {
                    device.whiteBalanceMode = .continuousAutoWhiteBalance
                    print("è®¾ç½®è‡ªåŠ¨ç™½å¹³è¡¡æ¨¡å¼æˆåŠŸ")
                } else {
                    print("è®¾å¤‡ä¸æ”¯æŒè‡ªåŠ¨ç™½å¹³è¡¡æ¨¡å¼")
                    device.unlockForConfiguration()
                    return false
                }
                
            case .sunny, .cloudy, .fluorescent, .incandescent:
                if device.isWhiteBalanceModeSupported(.locked) {
                    device.whiteBalanceMode = .locked
                    let temperatureAndTint = AVCaptureDevice.WhiteBalanceTemperatureAndTintValues(
                        temperature: state.temperature,
                        tint: state.tint
                    )
                    let gains = device.deviceWhiteBalanceGains(for: temperatureAndTint)
                    let normalizedGains = self.normalizeWhiteBalanceGains(gains, for: device)
                    device.setWhiteBalanceModeLocked(with: normalizedGains)
                    print("è®¾ç½®ç™½å¹³è¡¡æ¨¡å¼æˆåŠŸï¼š\(state.title)")
                } else {
                    print("è®¾å¤‡ä¸æ”¯æŒé”å®šç™½å¹³è¡¡æ¨¡å¼")
                    device.unlockForConfiguration()
                    return false
                }
            }
            
            device.unlockForConfiguration()
            return true
        } catch {
            print("è®¾ç½®ç™½å¹³è¡¡æ¨¡å¼å¤±è´¥: \(error.localizedDescription)")
            return false
        }
    }
    
    // è¾…åŠ©æ–¹æ³•ï¼šç¡®ä¿ç™½å¹³è¡¡å¢ç›Šå€¼åœ¨è®¾å¤‡æ”¯æŒçš„èŒƒå›´å†…
    private func normalizeWhiteBalanceGains(_ gains: AVCaptureDevice.WhiteBalanceGains, for device: AVCaptureDevice) -> AVCaptureDevice.WhiteBalanceGains {
        var normalizedGains = gains
        
        // ç¡®ä¿æ¯ä¸ªå¢ç›Šå€¼éƒ½åœ¨è®¾å¤‡æ”¯æŒçš„èŒƒå›´å†…
        let minGain: Float = 1.0  // æœ€å°å¢ç›Šå€¼é€šå¸¸ä¸º 1.0
        let maxGain: Float = device.maxWhiteBalanceGain
        
        normalizedGains.redGain = min(max(gains.redGain, minGain), maxGain)
        normalizedGains.greenGain = min(max(gains.greenGain, minGain), maxGain)
        normalizedGains.blueGain = min(max(gains.blueGain, minGain), maxGain)
        
        return normalizedGains
    }

    // MARK: - Camera Settings
    public func setExposure(_ value: Float) -> Bool {
        guard let device = captureDeviceInput?.device else { return false }

        do {
            try device.lockForConfiguration()
            
            // é¦–å…ˆåˆ‡æ¢åˆ°è‡ªåŠ¨æ›å…‰æ¨¡å¼
            if device.isExposureModeSupported(.continuousAutoExposure) {
                device.exposureMode = .continuousAutoExposure
                
                // è·å–è®¾å¤‡æ”¯æŒçš„æ›å…‰èŒƒå›´
                let minExposure = device.minExposureTargetBias
                let maxExposure = device.maxExposureTargetBias
                
                // å°†è¾“å…¥å€¼ (-2.0 åˆ° +2.0) æ˜ å°„åˆ°è®¾å¤‡æ”¯æŒçš„èŒƒå›´
                let normalizedValue = (value + 2.0) / 4.0  // å°† -2.0~2.0 æ˜ å°„åˆ° 0~1
                let exposureValue = minExposure + (maxExposure - minExposure) * normalizedValue
                
                // ç¡®ä¿å€¼åœ¨è®¾å¤‡æ”¯æŒçš„èŒƒå›´å†…
                let clampedValue = min(max(exposureValue, minExposure), maxExposure)
                
                // åº”ç”¨æ›å…‰å€¼
                device.setExposureTargetBias(clampedValue)
                print("ğŸ“¸ [Exposure] è®¾ç½®æ›å…‰å€¼ï¼š\(clampedValue) (åŸå§‹å€¼ï¼š\(value))")
                print("ğŸ“¸ [Exposure] è®¾å¤‡æ”¯æŒèŒƒå›´ï¼š[\(minExposure), \(maxExposure)]")
                
                // ç­‰å¾…æ›å…‰è°ƒæ•´ç”Ÿæ•ˆ
                device.exposurePointOfInterest = CGPoint(x: 0.5, y: 0.5)
            } else {
                print("âš ï¸ [Exposure] è®¾å¤‡ä¸æ”¯æŒè‡ªåŠ¨æ›å…‰æ¨¡å¼")
                device.unlockForConfiguration()
                return false
            }
            
            device.unlockForConfiguration()
            return true
        } catch {
            print("âš ï¸ [Exposure] è®¾ç½®æ›å…‰å€¼å¤±è´¥: \(error.localizedDescription)")
            return false
        }
    }
    
    public func setISO(_ value: Float) -> Bool {
        guard let device = captureDeviceInput?.device else { return false }
        
        do {
            try device.lockForConfiguration()
            
            if value == 0 {
                // Auto ISO
                if device.isExposureModeSupported(.continuousAutoExposure) {
                    device.exposureMode = .continuousAutoExposure
                    print("è®¾ç½® ISO ä¸ºè‡ªåŠ¨æ¨¡å¼")
                } else {
                    print("è®¾å¤‡ä¸æ”¯æŒè‡ªåŠ¨ ISO æ¨¡å¼")
                    device.unlockForConfiguration()
                    return false
                }
            } else {
                // Manual ISO
                if device.isExposureModeSupported(.custom) {
                    device.exposureMode = .custom
                    let isoValue = min(max(value, device.activeFormat.minISO), device.activeFormat.maxISO)
                    device.setExposureModeCustom(duration: device.exposureDuration, iso: isoValue)
                    print("è®¾ç½® ISO å€¼ä¸ºï¼š\(isoValue)")
                } else {
                    print("è®¾å¤‡ä¸æ”¯æŒè‡ªå®šä¹‰ ISO æ¨¡å¼")
                    device.unlockForConfiguration()
                    return false
                }
            }
            
            device.unlockForConfiguration()
            return true
        } catch {
            print("è®¾ç½® ISO å¤±è´¥: \(error.localizedDescription)")
            return false
        }
    }

    // MARK: - Focus Mode
    public private(set) var focusMode: SCFocusMode = .continuous {
        didSet {
            updateFocusMode()
            // ä¿å­˜è®¾ç½®
            SCCameraSettingsManager.shared.focusMode = focusMode
        }
    }
    
    public private(set) var focusState: SCFocusState = .focused {
        didSet {
            // é€šçŸ¥ä»£ç†ç„¦ç‚¹çŠ¶æ€å˜åŒ–
            if let delegate = self.delegate {
                delegate.didChangeValue(session: self, value: focusState, key: "focusState")
            }
            
            // æ›´æ–°å¯¹ç„¦é”å®šçŠ¶æ€
            if focusState == .locked {
                SCCameraSettingsManager.shared.isFocusLocked = true
            } else if focusState == .focused && focusMode != .locked {
                SCCameraSettingsManager.shared.isFocusLocked = false
            }
        }
    }
    
    private func updateFocusMode() {
        guard let device = captureDeviceInput?.device else { return }
        
        do {
            try device.lockForConfiguration()
            
            switch focusMode {
            case .auto:
                if device.isFocusModeSupported(.autoFocus) {
                    device.focusMode = .autoFocus
                }
            case .continuous:
                if device.isFocusModeSupported(.continuousAutoFocus) {
                    device.focusMode = .continuousAutoFocus
                }
            case .locked:
                if device.isFocusModeSupported(.locked) {
                    device.focusMode = .locked
                }
            case .manual:
                // æ‰‹åŠ¨å¯¹ç„¦æ¨¡å¼å°†åœ¨åç»­å®ç°
                break
            }
            
            device.unlockForConfiguration()
        } catch {
            print("âš ï¸ [Focus] æ›´æ–°å¯¹ç„¦æ¨¡å¼å¤±è´¥: \(error.localizedDescription)")
        }
    }

    // MARK: - Shutter Speed Control
    public func setShutterSpeed(_ value: Float, completion: ((Bool) -> Void)? = nil) -> Bool {
        guard let device = videoInput?.device else {
            print("ğŸ“¸ [Shutter Speed] æ— æ³•è·å–ç›¸æœºè®¾å¤‡")
            completion?(false)
            return false
        }
        
        do {
            try device.lockForConfiguration()
            
            // æ£€æŸ¥è®¾å¤‡æ˜¯å¦æ”¯æŒè‡ªå®šä¹‰æ›å…‰æ¨¡å¼
            if device.isExposureModeSupported(.custom) {
                if value == 0 {
                    // å€¼ä¸º0æ—¶ï¼Œåˆ‡æ¢åˆ°è‡ªåŠ¨æ›å…‰æ¨¡å¼
                    device.exposureMode = .continuousAutoExposure
                    print("ğŸ“¸ [Shutter Speed] åˆ‡æ¢åˆ°è‡ªåŠ¨æ›å…‰æ¨¡å¼")
                    device.unlockForConfiguration()
                    completion?(true)
                    return true
                } else {
                    // è®¾ç½®è‡ªå®šä¹‰æ›å…‰æ¨¡å¼
                    device.exposureMode = .custom
                    
                    // ç¦ç”¨è‡ªåŠ¨æ›å…‰è¡¥å¿
                    if device.isExposurePointOfInterestSupported {
                        device.exposurePointOfInterest = CGPoint(x: 0.5, y: 0.5)
                    }
                    
                    // å°†å¿«é—¨é€Ÿåº¦å€¼è½¬æ¢ä¸º CMTime
                    // value è¡¨ç¤ºç§’æ•°ï¼Œä¾‹å¦‚ value = 0.001 è¡¨ç¤º 1/1000 ç§’
                    let seconds = value
                    print("ğŸ“¸ [Shutter Speed] è®¾ç½®å¿«é—¨é€Ÿåº¦ï¼š\(seconds)ç§’ (1/\(Int(1/seconds))ç§’)")
                    let shutterSpeed = CMTimeMakeWithSeconds(Float64(seconds), preferredTimescale: 1000000)
                    
                    // è·å–è®¾å¤‡æ”¯æŒçš„å¿«é—¨é€Ÿåº¦èŒƒå›´
                    let minDuration = device.activeFormat.minExposureDuration
                    let maxDuration = device.activeFormat.maxExposureDuration
                    print("ğŸ“¸ [Shutter Speed] è®¾å¤‡æ”¯æŒçš„å¿«é—¨é€Ÿåº¦èŒƒå›´ï¼š[\(CMTimeGetSeconds(minDuration))ç§’, \(CMTimeGetSeconds(maxDuration))ç§’]")
                    
                    // ç¡®ä¿å¿«é—¨é€Ÿåº¦åœ¨æœ‰æ•ˆèŒƒå›´å†…
                    let clampedDuration = min(max(shutterSpeed, minDuration), maxDuration)
                    
                    // ä½¿ç”¨å›ºå®šçš„ ISO å€¼
                    let baseISO = device.activeFormat.minISO
                    print("ğŸ“¸ [Shutter Speed] ä½¿ç”¨å›ºå®š ISO å€¼ï¼š\(baseISO)")
                    
                    // è®¾ç½®æ›å…‰æ—¶é—´å’Œ ISO
                    device.setExposureModeCustom(duration: clampedDuration, iso: baseISO) { _ in
                        print("ğŸ“¸ [Shutter Speed] è®¾ç½®å®Œæˆ - å¿«é—¨é€Ÿåº¦: \(CMTimeGetSeconds(clampedDuration))ç§’, ISO: \(baseISO)")
                        completion?(true)
                    }
                }
                
                device.unlockForConfiguration()
                return true
            } else {
                print("âš ï¸ [Shutter Speed] è®¾å¤‡ä¸æ”¯æŒè‡ªå®šä¹‰æ›å…‰æ¨¡å¼")
                device.unlockForConfiguration()
                completion?(false)
                return false
            }
        } catch {
            print("ğŸ“¸ [Shutter Speed] è®¾ç½®å¤±è´¥: \(error.localizedDescription)")
            completion?(false)
            return false
        }
    }

}
